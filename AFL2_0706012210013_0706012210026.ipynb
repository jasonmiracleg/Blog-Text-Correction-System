{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc81f19f",
   "metadata": {},
   "source": [
    "# **Background Problem**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422e889d",
   "metadata": {},
   "source": [
    "# **Resource**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67640c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the years thereafter, most of the Oil fields and platforms were named after pagan “gods”.\n",
      "We love you Mr.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Load Dataset\n",
    "with open(\"en_US.blogs.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "    \n",
    "# Split into sentences using regex\n",
    "sentences = re.split(r'(?<=[.!?]) +', text)\n",
    "\n",
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b128a99",
   "metadata": {},
   "source": [
    "# **Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b4c8933",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/jasonmiracle/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first ten words in the text are: \n",
      "['in', 'the', 'years', 'thereafter', 'most', 'of', 'the', 'oil', 'fields', 'and']\n",
      "There are 435895 unique words in the vocabulary.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Lower Text\n",
    "text_lowercase = text.lower()\n",
    "\n",
    "# Remove Punctuation\n",
    "text_cleaned = re.sub(r'[^\\w\\s]', '', text_lowercase)  # removes punctuation\n",
    "\n",
    "words = word_tokenize(text_cleaned)\n",
    "\n",
    "vocabulary = set(words)\n",
    "\n",
    "print(f\"The first ten words in the text are: \\n{words[0:10]}\")\n",
    "print(f\"There are {len(vocabulary)} unique words in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2884c275",
   "metadata": {},
   "source": [
    "# **Building Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75d68b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 435895 key values pairs\n",
      "The count for the word 'i' is 769059\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary of Frequency\n",
    "word_count_dict = {}\n",
    "\n",
    "for word in words:\n",
    "    word_count_dict[word] = word_count_dict.get(word, 0) + 1\n",
    "    \n",
    "print(f\"There are {len(word_count_dict)} key values pairs\")\n",
    "print(f\"The count for the word 'i' is {word_count_dict.get('i',0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb8f80c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of probs is 435895\n",
      "P('i') is 0.0207\n"
     ]
    }
   ],
   "source": [
    "# Probability Computation Function\n",
    "def count_probability(word_count_dict):\n",
    "    probability = {}\n",
    "    \n",
    "    # Count Total Words in Corpus\n",
    "    total_words = sum(word_count_dict.values())\n",
    "    \n",
    "    for key, values in word_count_dict.items():\n",
    "        probability[key] = values/total_words\n",
    "        \n",
    "    return probability\n",
    "\n",
    "probabilities = count_probability(word_count_dict)\n",
    "print(f\"Length of probs is {len(probabilities)}\")\n",
    "print(f\"P('i') is {probabilities['i']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493084b2",
   "metadata": {},
   "source": [
    "## **Editing String**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "32a69fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete suggestion : ['own', 'dwn', 'don', 'dow']\n"
     ]
    }
   ],
   "source": [
    "# Delete Function\n",
    "def delete_letter(word, verbose=False):\n",
    "    split_letter = []\n",
    "    delete_letter = []\n",
    "    \n",
    "    # Split Word Each Position\n",
    "    split_letter = [(word[:i], word[i:]) for i in range(len(word))]\n",
    "    \n",
    "    # Delete Letter Each Position\n",
    "    delete_letter = [left + right[1:] for left, right in split_letter if right]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Delete suggestion : {delete_letter}\")\n",
    "    \n",
    "    return delete_letter\n",
    "\n",
    "result = delete_letter(\"down\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a13a28d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert suggestion : ['adown', 'bdown', 'cdown', 'ddown', 'edown', 'fdown', 'gdown', 'hdown', 'idown', 'jdown', 'kdown', 'ldown', 'mdown', 'ndown', 'odown', 'pdown', 'qdown', 'rdown', 'sdown', 'tdown', 'udown', 'vdown', 'wdown', 'xdown', 'ydown', 'zdown', 'daown', 'dbown', 'dcown', 'ddown', 'deown', 'dfown', 'dgown', 'dhown', 'diown', 'djown', 'dkown', 'dlown', 'dmown', 'dnown', 'doown', 'dpown', 'dqown', 'drown', 'dsown', 'dtown', 'duown', 'dvown', 'dwown', 'dxown', 'dyown', 'dzown', 'doawn', 'dobwn', 'docwn', 'dodwn', 'doewn', 'dofwn', 'dogwn', 'dohwn', 'doiwn', 'dojwn', 'dokwn', 'dolwn', 'domwn', 'donwn', 'doown', 'dopwn', 'doqwn', 'dorwn', 'doswn', 'dotwn', 'douwn', 'dovwn', 'dowwn', 'doxwn', 'doywn', 'dozwn', 'dowan', 'dowbn', 'dowcn', 'dowdn', 'dowen', 'dowfn', 'dowgn', 'dowhn', 'dowin', 'dowjn', 'dowkn', 'dowln', 'dowmn', 'downn', 'dowon', 'dowpn', 'dowqn', 'dowrn', 'dowsn', 'dowtn', 'dowun', 'dowvn', 'dowwn', 'dowxn', 'dowyn', 'dowzn', 'downa', 'downb', 'downc', 'downd', 'downe', 'downf', 'downg', 'downh', 'downi', 'downj', 'downk', 'downl', 'downm', 'downn', 'downo', 'downp', 'downq', 'downr', 'downs', 'downt', 'downu', 'downv', 'downw', 'downx', 'downy', 'downz']\n"
     ]
    }
   ],
   "source": [
    "# Insert Function\n",
    "def insert_letter(word, verbose=False):\n",
    "    split_letter = []\n",
    "    insert_letter = []\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    \n",
    "    # Split Word Each Position\n",
    "    split_letter = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    \n",
    "    # Insert Letter Each Position\n",
    "    for left, right in split_letter:\n",
    "        for letter in letters:\n",
    "            new_word = left + letter + right\n",
    "            insert_letter.append(new_word)\n",
    "    \n",
    "    if verbose: print(f\"Insert suggestion : {insert_letter}\")\n",
    "    \n",
    "    return insert_letter\n",
    "\n",
    "result = insert_letter('down', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e16fb76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swap suggestion : ['odwn', 'dwon', 'donw']\n"
     ]
    }
   ],
   "source": [
    "# Swap Function\n",
    "def swap_letter(word, verbose=False):\n",
    "    split_letter = []\n",
    "    swap_letter = []\n",
    "    \n",
    "    # Split Word Each Position\n",
    "    split_letter = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    \n",
    "    # Swap Letter\n",
    "    for left, right in split_letter:\n",
    "        if len(right) > 1:\n",
    "            new_word = left + right[1] + right[0] + right[2:]\n",
    "            swap_letter.append(new_word)\n",
    "            \n",
    "    if verbose: print(f\"Swap suggestion : {swap_letter}\")\n",
    "\n",
    "    return swap_letter\n",
    "\n",
    "result = swap_letter(\"down\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4b651ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert suggestion : ['aown', 'bown', 'cown', 'eown', 'fown', 'gown', 'hown', 'iown', 'jown', 'kown', 'lown', 'mown', 'nown', 'oown', 'pown', 'qown', 'rown', 'sown', 'town', 'uown', 'vown', 'wown', 'xown', 'yown', 'zown', 'dawn', 'dbwn', 'dcwn', 'ddwn', 'dewn', 'dfwn', 'dgwn', 'dhwn', 'diwn', 'djwn', 'dkwn', 'dlwn', 'dmwn', 'dnwn', 'dpwn', 'dqwn', 'drwn', 'dswn', 'dtwn', 'duwn', 'dvwn', 'dwwn', 'dxwn', 'dywn', 'dzwn', 'doan', 'dobn', 'docn', 'dodn', 'doen', 'dofn', 'dogn', 'dohn', 'doin', 'dojn', 'dokn', 'doln', 'domn', 'donn', 'doon', 'dopn', 'doqn', 'dorn', 'dosn', 'dotn', 'doun', 'dovn', 'doxn', 'doyn', 'dozn', 'dowa', 'dowb', 'dowc', 'dowd', 'dowe', 'dowf', 'dowg', 'dowh', 'dowi', 'dowj', 'dowk', 'dowl', 'dowm', 'dowo', 'dowp', 'dowq', 'dowr', 'dows', 'dowt', 'dowu', 'dowv', 'doww', 'dowx', 'dowy', 'dowz']\n"
     ]
    }
   ],
   "source": [
    "# Replace Function\n",
    "def replace_letter(word, verbose=False):\n",
    "    split_letter = []\n",
    "    replace_letter = []\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    \n",
    "    # Split Word Each Position\n",
    "    split_letter = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    \n",
    "    # Replace Letter Each Position\n",
    "    for left, right in split_letter:\n",
    "        if right:\n",
    "            for letter in letters:\n",
    "                if right[0] != letter:\n",
    "                    new_word = left + letter + right[1:]\n",
    "                    replace_letter.append(new_word)\n",
    "            \n",
    "    if verbose: print(f\"Insert suggestion : {replace_letter}\")\n",
    "    \n",
    "    return replace_letter\n",
    "\n",
    "result = replace_letter('down', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "70dff02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edit results : {'dofn', 'dowqn', 'daown', 'dswn', 'dowe', 'dtwn', 'downt', 'dowkn', 'sdown', 'dohn', 'dcown', 'dqwn', 'dxown', 'hown', 'dowr', 'downv', 'dnwn', 'doxwn', 'dzown', 'donwn', 'ldown', 'doiwn', 'town', 'doswn', 'downb', 'downd', 'djwn', 'dvown', 'dhwn', 'dovn', 'rdown', 'dqown', 'downm', 'dowjn', 'dowj', 'doywn', 'xdown', 'ydown', 'odown', 'downg', 'downo', 'ddwn', 'mdown', 'dbown', 'duown', 'dowzn', 'downi', 'dotn', 'fown', 'doqwn', 'lown', 'dopn', 'qown', 'doyn', 'aown', 'dowq', 'kown', 'dewn', 'dogwn', 'dowm', 'downl', 'jown', 'dsown', 'dobn', 'dowfn', 'downa', 'qdown', 'downc', 'rown', 'bdown', 'dowb', 'xown', 'downe', 'downz', 'ddown', 'cown', 'dowyn', 'dowf', 'dowwn', 'own', 'drwn', 'domwn', 'gdown', 'bown', 'docn', 'dowrn', 'dhown', 'dkown', 'downr', 'wown', 'dywn', 'dfown', 'diown', 'dokwn', 'adown', 'dmown', 'dzwn', 'doin', 'dowz', 'dowmn', 'ndown', 'dozwn', 'doxn', 'dodwn', 'mown', 'dowsn', 'dotwn', 'fdown', 'dwon', 'dvwn', 'dowt', 'dowln', 'dowy', 'dxwn', 'dowo', 'doqn', 'iown', 'dwwn', 'dopwn', 'djown', 'pown', 'pdown', 'dojwn', 'dowin', 'zdown', 'donw', 'sown', 'gown', 'eown', 'douwn', 'downp', 'downs', 'dlown', 'dfwn', 'dokn', 'dowg', 'downf', 'cdown', 'dowhn', 'dawn', 'dowp', 'dodn', 'yown', 'kdown', 'odwn', 'dowdn', 'dowd', 'dyown', 'doon', 'docwn', 'dwown', 'downh', 'downk', 'dowgn', 'dohwn', 'dowc', 'dowon', 'hdown', 'downy', 'dofwn', 'downx', 'dovwn', 'downq', 'zown', 'dowcn', 'dojn', 'dowun', 'doawn', 'dgwn', 'domn', 'idown', 'doun', 'dows', 'dowv', 'doln', 'edown', 'deown', 'dowan', 'doewn', 'dow', 'donn', 'dmwn', 'dwn', 'dcwn', 'dpwn', 'drown', 'oown', 'doen', 'downw', 'dowvn', 'doww', 'dobwn', 'dowen', 'wdown', 'dowxn', 'dowu', 'dowi', 'dowtn', 'dorwn', 'downn', 'jdown', 'duwn', 'dogn', 'nown', 'dowh', 'dolwn', 'dowa', 'udown', 'dkwn', 'dowbn', 'dtown', 'dowx', 'downj', 'diwn', 'downu', 'doown', 'vown', 'dlwn', 'dgown', 'vdown', 'dorn', 'dowk', 'dnown', 'dpown', 'dosn', 'dowpn', 'doan', 'tdown', 'dowl', 'dozn', 'don', 'uown', 'dbwn'}\n"
     ]
    }
   ],
   "source": [
    "# Function\n",
    "def editing_one_letter(word):\n",
    "    letters = word.lower()\n",
    "    suggestions = set(delete_letter(letters) + insert_letter(letters) + swap_letter(letters) + replace_letter(letters))\n",
    "    print(f\"Edit results : {suggestions}\")\n",
    "    return suggestions\n",
    "\n",
    "result = editing_one_letter(\"down\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8a91389c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edit results : {'tnesw', 'nesf', 'neskw', 'neswx', 'nese', 'naesw', 'news', 'ntsw', 'neswp', 'iesw', 'xesw', 'neswi', 'nesu', 'neaw', 'neswk', 'hnesw', 'jesw', 'nmsw', 'nsw', 'nesk', 'bnesw', 'onesw', 'lesw', 'nesdw', 'neshw', 'eesw', 'nuesw', 'nqsw', 'negw', 'oesw', 'neslw', 'nejw', 'neisw', 'nasw', 'ncsw', 'nelw', 'neswd', 'nenw', 'nepw', 'nespw', 'nlesw', 'nesrw', 'nbesw', 'nesl', 'unesw', 'nnesw', 'neswj', 'nesgw', 'nwesw', 'netw', 'resw', 'lnesw', 'necsw', 'neyw', 'nssw', 'yesw', 'nisw', 'desw', 'nrsw', 'nnsw', 'ngesw', 'neosw', 'nepsw', 'nelsw', 'znesw', 'nescw', 'ynesw', 'nesj', 'niesw', 'netsw', 'cnesw', 'ndesw', 'ensw', 'nezw', 'nexsw', 'neswl', 'nzsw', 'vnesw', 'nesnw', 'neksw', 'nesc', 'nqesw', 'nesv', 'pesw', 'ncesw', 'pnesw', 'mesw', 'neswy', 'nosw', 'njesw', 'neswz', 'nesx', 'neww', 'gesw', 'mnesw', 'neesw', 'fesw', 'neswu', 'nersw', 'nlsw', 'nesp', 'nemsw', 'newsw', 'neswa', 'neswg', 'zesw', 'enesw', 'nesn', 'nfsw', 'nesa', 'neso', 'nmesw', 'jnesw', 'qnesw', 'nezsw', 'nesiw', 'neswv', 'nesg', 'nexw', 'nesuw', 'nesew', 'nesow', 'neusw', 'nesi', 'nevw', 'nvesw', 'nesfw', 'vesw', 'nusw', 'nysw', 'nevsw', 'snesw', 'npesw', 'nefsw', 'kesw', 'ndsw', 'nedw', 'cesw', 'necw', 'nemw', 'nesy', 'nebsw', 'nehw', 'nesyw', 'neiw', 'wnesw', 'nensw', 'neswf', 'hesw', 'knesw', 'neswc', 'tesw', 'nvsw', 'nesh', 'nsesw', 'ntesw', 'nesq', 'nhsw', 'nesjw', 'anesw', 'nest', 'neew', 'ness', 'gnesw', 'noesw', 'neswh', 'neswn', 'esw', 'uesw', 'negsw', 'nyesw', 'nesxw', 'nesws', 'ngsw', 'neswq', 'rnesw', 'nxsw', 'neqsw', 'nxesw', 'nsew', 'xnesw', 'nbsw', 'nebw', 'neqw', 'nesb', 'besw', 'nesaw', 'nkesw', 'nhesw', 'nehsw', 'neow', 'nerw', 'neswe', 'nesmw', 'nzesw', 'neasw', 'nes', 'nesww', 'nesm', 'nfesw', 'nesvw', 'new', 'neswb', 'nessw', 'neszw', 'neuw', 'nksw', 'nejsw', 'nestw', 'wesw', 'neswo', 'nekw', 'nefw', 'neswt', 'sesw', 'neysw', 'inesw', 'nesz', 'neswr', 'npsw', 'nesbw', 'njsw', 'nresw', 'nesr', 'aesw', 'nesd', 'nedsw', 'neswm', 'nwsw', 'qesw', 'fnesw', 'dnesw', 'nesqw'}\n",
      "entered word =  nesw \n",
      "suggestions =  {'nesn', 'nasw', 'nsw', 'nes', 'news', 'nssw', 'new', 'nehw', 'nest', 'ness'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('new', 0.001462007029042426),\n",
       " ('news', 0.0002067017207528097),\n",
       " ('nest', 1.6601791422088467e-05)]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def autocorrection(word, vocabulary, probabilities, n=3):\n",
    "    suggestions = []\n",
    "    n_best = []\n",
    "    \n",
    "    if word in vocabulary:\n",
    "        suggestions.append(word)\n",
    "    else:\n",
    "        one_edit = editing_one_letter(word)\n",
    "        valid_result = one_edit.intersection(vocabulary)\n",
    "        if valid_result:\n",
    "            suggestions = valid_result\n",
    "            \n",
    "    words_probability = {word: probabilities.get(word, 0) for word in suggestions}\n",
    "    \n",
    "    n_best = sorted(words_probability.items(), key=lambda x: -x[1])[:n]\n",
    "    \n",
    "    print(\"entered word = \", word, \"\\nsuggestions = \", suggestions)\n",
    "\n",
    "    return n_best\n",
    "\n",
    "autocorrection(\"nesw\", vocabulary, probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff354392",
   "metadata": {},
   "source": [
    "# **Evaluation Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44d47ff",
   "metadata": {},
   "source": [
    "# **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d5bd02",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
